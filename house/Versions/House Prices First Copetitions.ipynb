{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *House Prices First Try Copetitions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 14920.21747645548\n",
      "Mean Absolute Error : 12056.9087302012\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "data = pd.read_csv('../house/train.csv')\n",
    "data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = data.SalePrice\n",
    "X = data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "my_imputer = Imputer()\n",
    "train_X = my_imputer.fit_transform(train_X)\n",
    "test_X = my_imputer.transform(test_X)\n",
    "\n",
    "my_model = XGBRegressor(n_estimators=400, learning_rate=0.05, random_state=101)\n",
    "my_model.fit(train_X, train_y, early_stopping_rounds=10, \n",
    "             eval_set=[(test_X, test_y)], verbose=False)\n",
    "\n",
    "# make predictions\n",
    "predictions = my_model.predict(test_X)\n",
    "\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, test_y)))\n",
    "\n",
    "final = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=400,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=101,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "\n",
    "X_scaled = my_imputer.transform(X)\n",
    "\n",
    "final.fit(X_scaled, y)\n",
    "\n",
    "# make predictions\n",
    "predictions = my_model.predict(X_scaled)\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, y)))\n",
    "\n",
    "test = pd.read_csv('../house/test.csv')\n",
    "\n",
    "X_test = test.select_dtypes(exclude=['object'])\n",
    "X_test = my_imputer.transform(X_test)\n",
    "\n",
    "# make predictions\n",
    "predictions = my_model.predict(X_test)\n",
    "\n",
    "my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('SalePrice_1_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmy_model = Pipeline([\\n    ('input', Imputer()),\\n    ('scl', StandardScaler()),\\n    ('clf', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\n       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\\n       max_depth=3, min_child_weight=1, missing=None, \\n       n_jobs=1, nthread=None, objective='reg:linear', random_state=101,\\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\\n       silent=True, subsample=1))])\\n\\n\\nscores = (-1 *cross_val_score(estimator = my_model, X = X , y = y, scoring='neg_mean_absolute_error', cv=6))\\nprint(scores)\\nprint(scores.mean())\\n\\n# make predictions\\npredictions = cross_val_predict(estimator = my_model, X = X , y = y, cv=6)\\nprint(metrics.mean_absolute_error(y_pred = predictions , y_true = y))\\n\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "data = pd.read_csv('../house/train.csv')\n",
    "y = data.SalePrice\n",
    "\n",
    "def features_seletc(X):\n",
    "    return X.drop(['SalePrice', 'Id'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "X = features_seletc(data)\n",
    "\n",
    "'''\n",
    "my_model = Pipeline([\n",
    "    ('input', Imputer()),\n",
    "    ('scl', StandardScaler()),\n",
    "    ('clf', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, \n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=101,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1))])\n",
    "\n",
    "\n",
    "scores = (-1 *cross_val_score(estimator = my_model, X = X , y = y, scoring='neg_mean_absolute_error', cv=6))\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "# make predictions\n",
    "predictions = cross_val_predict(estimator = my_model, X = X , y = y, cv=6)\n",
    "print(metrics.mean_absolute_error(y_pred = predictions , y_true = y))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Pipeline([\n",
    "    ('input', Imputer()),\n",
    "    ('scl', StandardScaler()),\n",
    "    ('clf', XGBRegressor(base_score=0.5, colsample_bylevel=1,\n",
    "       colsample_bytree=1, booster='gbtree', gamma=0, max_delta_step=0,\n",
    "       min_child_weight=1, missing=None, max_depth = 3,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=101,\n",
    "       reg_alpha=0, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1))])\n",
    "\n",
    "n_est = [575, 650, 600, 550]\n",
    "#max_depth = [2, 3, 6]\n",
    "learning_rate = [0.05, 0.1]\n",
    "reg_lambda = [1, 0.1]\n",
    "#booster = ['gbtree', 'gblinear', 'dart']\n",
    "clf = GridSearchCV(estimator = my_model, param_grid = dict(clf__n_estimators= n_est, \n",
    "                                                           #clf__booster = booster,\n",
    "                                                           clf__learning_rate = learning_rate,\n",
    "                                                           clf__reg_lambda = reg_lambda\n",
    "                                                           #clf__max_depth = max_depth\n",
    "                                                          ), \n",
    "                   scoring='neg_mean_absolute_error', cv=6, verbose=1, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 16 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=3)]: Done  96 out of  96 | elapsed:   42.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('input', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_de...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'clf__n_estimators': [575, 650, 600, 550], 'clf__learning_rate': [0.05, 0.1], 'clf__reg_lambda': [1, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15913.275113709333"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../house/test.csv')\n",
    "X_t = test.drop(['Id'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "predictions = clf.predict(X = X_t)\n",
    "\n",
    "my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('SalePrice_2_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('input',\n",
       "   Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)),\n",
       "  ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('clf', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "          colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "          max_depth=3, min_child_weight=1, missing=None, n_estimators=550,\n",
       "          n_jobs=1, nthread=None, objective='reg:linear', random_state=101,\n",
       "          reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "          silent=True, subsample=1))],\n",
       " 'input': Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0),\n",
       " 'scl': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'clf': XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "        max_depth=3, min_child_weight=1, missing=None, n_estimators=550,\n",
       "        n_jobs=1, nthread=None, objective='reg:linear', random_state=101,\n",
       "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=1),\n",
       " 'input__axis': 0,\n",
       " 'input__copy': True,\n",
       " 'input__missing_values': 'NaN',\n",
       " 'input__strategy': 'mean',\n",
       " 'input__verbose': 0,\n",
       " 'scl__copy': True,\n",
       " 'scl__with_mean': True,\n",
       " 'scl__with_std': True,\n",
       " 'clf__base_score': 0.5,\n",
       " 'clf__booster': 'gbtree',\n",
       " 'clf__colsample_bylevel': 1,\n",
       " 'clf__colsample_bytree': 1,\n",
       " 'clf__gamma': 0,\n",
       " 'clf__learning_rate': 0.1,\n",
       " 'clf__max_delta_step': 0,\n",
       " 'clf__max_depth': 3,\n",
       " 'clf__min_child_weight': 1,\n",
       " 'clf__missing': None,\n",
       " 'clf__n_estimators': 550,\n",
       " 'clf__n_jobs': 1,\n",
       " 'clf__nthread': None,\n",
       " 'clf__objective': 'reg:linear',\n",
       " 'clf__random_state': 101,\n",
       " 'clf__reg_alpha': 0,\n",
       " 'clf__reg_lambda': 1,\n",
       " 'clf__scale_pos_weight': 1,\n",
       " 'clf__seed': None,\n",
       " 'clf__silent': True,\n",
       " 'clf__subsample': 1}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_score', 'booster', 'colsample_bylevel', 'colsample_bytree', 'gamma', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_estimators', 'n_jobs', 'nthread', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'seed', 'silent', 'subsample'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Submission: \n",
    "Training the best model with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEA training all data: 6049.851522367295\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data = pd.read_csv('../house/train.csv')\n",
    "y = data.SalePrice\n",
    "\n",
    "def features_seletc(X):\n",
    "    return X.drop(['SalePrice', 'Id'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "X = features_seletc(data)\n",
    "\n",
    "my_model = Pipeline([\n",
    "    ('input', Imputer()),\n",
    "    ('scl', StandardScaler()),\n",
    "    ('clf', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "        colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "        max_depth=3, min_child_weight=1, missing=None, n_estimators=550,\n",
    "        n_jobs=1, nthread=None, objective='reg:linear', random_state=101,\n",
    "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "        silent=True, subsample=1))])\n",
    "\n",
    "my_model.fit(X, y)\n",
    "predicted_home_prices = my_model.predict(X)\n",
    "print(\"MEA training all data:\",mean_absolute_error(y, predicted_home_prices))\n",
    "\n",
    "test = pd.read_csv('../house/test.csv')\n",
    "X_t = test.drop(['Id'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "predictions = my_model.predict(X = X_t)\n",
    "\n",
    "my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('SalePrice_3_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "data = pd.read_csv('../house/train.csv')\n",
    "y = data.SalePrice\n",
    "#X = data.drop(['SalePrice', 'Id'], axis=1).select_dtypes(exclude=['object'])\n",
    "#del data\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total training observations are 1,460 and have 79 features ( 3 float64, 33 int64, 43 object ) with 19 nulls, wheres:\n",
    " - 14 has few null, so are good candidates for imputer strategies:\n",
    "<ul><b>See below all Ordinal that doesn't have NA. We can infer thar nan are NA!</b>\n",
    "    <li>GarageFinish___1379  object. Interior finish of the garage. All nan has GarageType equal a NA, so we can infer NA too</li>\n",
    "    <li>GarageQual_____1379  object: Garage quality. </li>\n",
    "    <li>GarageCond_____1379  object: Garage condition. </li>\n",
    "    <li>BsmtExposure___1422  object: Refers to walkout or garden level walls.</li>\n",
    "    <li>BsmtFinType2___1422  object: Rating of basement finished area (if multiple types). Only not infer NA to Id 333, becouse has BsmtFinSF2 and BsmtFinSF1, for this consedere GLQ, becouse is what we found in BsmtFinType1!</li>\n",
    "    <li>BsmtQual_______1423  object: Evaluates the height of the basement Doesn't have PO and NA.</li>\n",
    "    <li>BsmtCond_______1423  object: Ealuates the general condition of the basement. Doesn't have Ex and NA.</li>\n",
    "    <li>BsmtFinType1___1423  object: Rating of basement finished area (if multiple types). </li>\n",
    "</ul>    \n",
    "<ul><b>Numeric and Categorical datas with diferents inputer strategies</b>\n",
    "    <li>LotFrontage____1201  float64: is the linear feet of street connected to property. Some property realy don't have directle Lot Frontage, so we can consider 0 to nan.</li>\n",
    "    <li>GarageType_____1379  object: Doesn't have NA. We can infer that nan are NA</li>\n",
    "    <li>GarageYrBlt____1379  float64. All nan has GarageType equal a NA, so we can infer to 0</li>\n",
    "    <li>MasVnrType_____1452  object: is the masonry veneer type, hasn't CBlock in the training data! CBlock is the nan?</li>\n",
    "    <li>MasVnrArea_____1452  float64: Masonry veneer area in square feet, null when MasVnrType is null. We can infer 0</li>\n",
    "    <li>Electrical_____1459  object. Only one, can apply the most commun.</li>\n",
    "</ul>\n",
    "<p>\n",
    " - 5 has more than 47% of nulls, maybe candidates to exclude or substitute for nulls presence flags\n",
    "<ul><b>See below all Ordinal that doesn't have NA. We can infer thar nan are NA!</b>\n",
    "    <li>PoolQC        7  object: Pool quality. Does´t have TA and NA explicit in the data</li>\n",
    "    <li>Fence       281  object: Fence quality.</li>\n",
    "    <li>FireplaceQu 770  object: Fireplace quality.</li>\n",
    "</ul>\n",
    "<ul><b> Categorical datas that does´t have NA explicit in the data, but has nan. Infer NA to nan records</b>\n",
    "    <li>MiscFeature 54  object: Miscellaneous feature not covered in other categories. Does´t have Elev and NA explicit in the data</li>\n",
    "    <li>Alley       91  object: is the type of alley access to property.</li>\n",
    "</ul>\n",
    "Some numeric data are ordinal or categorical already translate to codes.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data quality of training data compare to the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass has 1460 observations. See below the MSSubClass not found in the training data:\n",
      "150 : 37257 STORY PUD - ALL AGES\n"
     ]
    }
   ],
   "source": [
    "# Identifies the type of dwelling involved in the sale.\n",
    "MSSubClass = {}\n",
    "MSSubClass[20] = '1-STORY 1946 & NEWER ALL STYLES'\n",
    "MSSubClass[30] = '1-STORY 1945 & OLDER'\n",
    "MSSubClass[40] = '1-STORY W/FINISHED ATTIC ALL AGES'\n",
    "MSSubClass[45] = '37257 STORY - UNFINISHED ALL AGES'\n",
    "MSSubClass[50] = '37257 STORY FINISHED ALL AGES'\n",
    "MSSubClass[60] = '2-STORY 1946 & NEWER'\n",
    "MSSubClass[70] = '2-STORY 1945 & OLDER'\n",
    "MSSubClass[75] = '37258 STORY ALL AGES'\n",
    "MSSubClass[80] = 'SPLIT OR MULTI-LEVEL'\n",
    "MSSubClass[85] = 'SPLIT FOYER'\n",
    "MSSubClass[90] = 'DUPLEX - ALL STYLES AND AGES'\n",
    "MSSubClass[120] = '1-STORY PUD (Planned Unit Development) - 1946 & NEWER'\n",
    "MSSubClass[150] = '37257 STORY PUD - ALL AGES'\n",
    "MSSubClass[160] = '2-STORY PUD - 1946 & NEWER'\n",
    "MSSubClass[180] = 'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER'\n",
    "MSSubClass[190] = '2 FAMILY CONVERSION - ALL STYLES AND AGES'\n",
    "\n",
    "a = np.sort(data.MSSubClass.unique())\n",
    "print(\"MSSubClass has\",data.MSSubClass.count(),\"observations. See below the MSSubClass not found in the training data:\")\n",
    "for i in  MSSubClass.keys():\n",
    " if [i] not in a: print(i, \":\", MSSubClass[i])\n",
    "# Note: Test dataset has the 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning has 1460 observations. See below the MSZoning not found in the training data:\n",
      "A : Agriculture\n",
      "C : Commercial\n",
      "I : Industrial\n",
      "RP : Residential Low Density Park\n"
     ]
    }
   ],
   "source": [
    "# Identifies the general zoning classification of the sale.\n",
    "MSZoning = {}\n",
    "MSZoning['A']='Agriculture'\n",
    "MSZoning['C']='Commercial'\n",
    "MSZoning['FV']='Floating Village Residential'\n",
    "MSZoning['I']='Industrial'\n",
    "MSZoning['RH']='Residential High Density'\n",
    "MSZoning['RL']='Residential Low Density'\n",
    "MSZoning['RP']='Residential Low Density Park' \n",
    "MSZoning['RM']='Residential Medium Density'\n",
    "MSZoning['C (all)']='Commercial' # Exist in the training data and we don't know if is a substitute of 'C'\n",
    "a = np.sort(data.MSZoning.unique())\n",
    "print(\"MSZoning has\",data.MSZoning.count(),\"observations. See below the MSZoning not found in the training data:\")\n",
    "for i in  MSZoning.keys():\n",
    " if [i] not in a: print(i, \":\", MSZoning[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention: General shape is ordinal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotShape has 1460 observations and all class are found in the training data!\n"
     ]
    }
   ],
   "source": [
    "# General shape of property\n",
    "LotShape = {}\n",
    "LotShape['Reg'] = 'Regular'\n",
    "LotShape['IR1'] = 'Slightly irregular'\n",
    "LotShape['IR2'] = 'Moderately Irregular'\n",
    "LotShape['IR3'] = 'Irregular'\n",
    "\n",
    "a = np.sort(data.LotShape.unique())\n",
    "print(\"LotShape has\",data.LotShape.count(),\"observations and all class are found in the training data!\")\n",
    "for i in  LotShape.keys():\n",
    " if [i] not in a: print(i, \":\", LotShape[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilities has 1460 observations. See below the Utilities not found in the training data:\n",
      "NoSewr : Electricity, Gas, and Water (Septic Tank)\n",
      "ELO : Electricity only\n"
     ]
    }
   ],
   "source": [
    "# Utilities: Type of utilities available\n",
    "Utilities = {}\n",
    "Utilities['AllPub'] = 'All public Utilities (E,G,W,& S)'\n",
    "Utilities['NoSewr'] = 'Electricity, Gas, and Water (Septic Tank)'\n",
    "Utilities['NoSeWa'] = 'Electricity and Gas Only'\n",
    "Utilities['ELO'] = 'Electricity only'\n",
    "\n",
    "a = np.sort(data.Utilities.unique())\n",
    "print('Utilities has',data.Utilities.count(),\"observations. See below the Utilities not found in the training data:\")\n",
    "for i in  Utilities.keys():\n",
    "   if [i] not in a: print(i, ':', Utilities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotConfig has 1460 observations and all class are found in the training data!\n"
     ]
    }
   ],
   "source": [
    "# LotConfig: Lot configuration\n",
    "LotConfig = {}\n",
    "LotConfig['Inside'] = 'Inside lot'\n",
    "LotConfig['Corner'] = 'Corner lot'\n",
    "LotConfig['CulDSac'] = 'Cul-de-sac'\n",
    "LotConfig['FR2'] = 'Frontage on 2 sides of property'\n",
    "LotConfig['FR3'] = 'Frontage on 3 sides of property'\n",
    "\n",
    "a = np.sort(data.LotConfig.unique())\n",
    "print('LotConfig has',data.LotConfig.count(),'observations and all class are found in the training data!')\n",
    "for i in  LotConfig.keys():\n",
    "   if [i] not in a: print(i, ':', LotConfig[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention: LandSlope is ordinal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LandSlope has 1460 observations and all class are found in the training data!\n"
     ]
    }
   ],
   "source": [
    "# LandSlope: Slope of property\n",
    "LandSlope = {}\n",
    "LandSlope['Gtl'] = 'Gentle slope'\n",
    "LandSlope['Mod'] = 'Moderate Slope'\n",
    "LandSlope['Sev'] = 'Severe Slope'\n",
    "\n",
    "a = np.sort(data.LandSlope.unique())\n",
    "print('LandSlope has',data.LandSlope.count(),'observations and all class are found in the training data!')\n",
    "for i in  LandSlope.keys():\n",
    "   if [i] not in a: print(i, ':', LandSlope[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighborhood has 1460 observations and all class are found in the training data!\n"
     ]
    }
   ],
   "source": [
    "# Neighborhood: Physical locations within Ames city limits\n",
    "Neighborhood = {}\n",
    "Neighborhood['Blmngtn'] = 'Bloomington Heights'\n",
    "Neighborhood['Blueste'] = 'Bluestem'\n",
    "Neighborhood['BrDale'] = 'Briardale'\n",
    "Neighborhood['BrkSide'] = 'Brookside'\n",
    "Neighborhood['ClearCr'] = 'Clear Creek'\n",
    "Neighborhood['CollgCr'] = 'College Creek'\n",
    "Neighborhood['Crawfor'] = 'Crawford'\n",
    "Neighborhood['Edwards'] = 'Edwards'\n",
    "Neighborhood['Gilbert'] = 'Gilbert'\n",
    "Neighborhood['IDOTRR'] = 'Iowa DOT and Rail Road'\n",
    "Neighborhood['MeadowV'] = 'Meadow Village'\n",
    "Neighborhood['Mitchel'] = 'Mitchell'\n",
    "Neighborhood['NAmes'] = 'North Ames'\n",
    "Neighborhood['NoRidge'] = 'Northridge'\n",
    "Neighborhood['NPkVill'] = 'Northpark Villa'\n",
    "Neighborhood['NridgHt'] = 'Northridge Heights'\n",
    "Neighborhood['NWAmes'] = 'Northwest Ames'\n",
    "Neighborhood['OldTown'] = 'Old Town'\n",
    "Neighborhood['SWISU'] = 'South & West of Iowa State University'\n",
    "Neighborhood['Sawyer'] = 'Sawyer'\n",
    "Neighborhood['SawyerW'] = 'Sawyer West'\n",
    "Neighborhood['Somerst'] = 'Somerset'\n",
    "Neighborhood['StoneBr'] = 'Stone Brook'\n",
    "Neighborhood['Timber'] = 'Timberland'\n",
    "Neighborhood['Veenker'] = 'Veenker'\n",
    "\n",
    "a = np.sort(data.Neighborhood.unique())\n",
    "print('Neighborhood has',data.Neighborhood.count(),'observations and all class are found in the training data!')\n",
    "for i in  Neighborhood.keys():\n",
    "   if [i] not in a: print(i, ':', Neighborhood[i])\n",
    "#  here we found NAmes as Names in the explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition1 has 1460 observations and all class are found in the training data!\n"
     ]
    }
   ],
   "source": [
    "# Condition1: Proximity to various conditions\n",
    "Condition1 = {}\n",
    "Condition1['Artery'] = 'Adjacent to arterial street'\n",
    "Condition1['Feedr'] = 'Adjacent to feeder street'\n",
    "Condition1['Norm'] = 'Normal'\n",
    "Condition1['RRNn'] = 'Within 200 of North-South Railroad'\n",
    "Condition1['RRAn'] = 'Adjacent to North-South Railroad'\n",
    "Condition1['PosN'] = 'Near positive off-site feature--park, greenbelt, etc.'\n",
    "Condition1['PosA'] = 'Adjacent to postive off-site feature'\n",
    "Condition1['RRNe'] = 'Within 200 of East-West Railroad'\n",
    "Condition1['RRAe'] = 'Adjacent to East-West Railroad'\n",
    "\n",
    "a = np.sort(data.Condition1.unique())\n",
    "print('Condition1 has',data.Condition1.count(),'observations and all class are found in the training data!')\n",
    "for i in  Condition1.keys():\n",
    "   if [i] not in a: print(i, ':', Condition1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition2 has 1460 . See below the Condition2 not found in the training data:\n",
      "RRNe : Within 200 of East-West Railroad\n"
     ]
    }
   ],
   "source": [
    "a = np.sort(data.Condition2.unique())\n",
    "print('Condition2 has',data.Condition2.count(),\". See below the Condition2 not found in the training data:\")\n",
    "for i in  Condition1.keys():\n",
    "   if [i] not in a: print(i, ':', Condition1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some problems of speling disacord from explanation file sugest first make a upper case os all string data before code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BldgType has 1460 observations and all class are found in the training data with some corrections!\n"
     ]
    }
   ],
   "source": [
    "# BldgType: Type of dwelling\n",
    "BldgType = {}\n",
    "BldgType['1Fam'] = 'Single-family Detached'\n",
    "BldgType['2fmCon'] = 'Two-family Conversion; originally built as one-family dwelling'\n",
    "BldgType['Duplex'] = 'Duplex'\n",
    "BldgType['TwnhsE'] = 'Townhouse End Unit'\n",
    "BldgType['Twnhs'] = 'Townhouse Inside Unit'\n",
    "\n",
    "a = np.sort(data.BldgType.unique())\n",
    "print('BldgType has',data.BldgType.count(),'observations and all class are found in the training data with some corrections!')\n",
    "\n",
    "for i in  BldgType.keys():\n",
    "   if [i] not in a: print(i, ':', BldgType[i])\n",
    "# Some problems of speling disacord from explanation file: Twnhs is not TwnshI, Duplex instead Duplx and 2fmCon instead 2FmCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HouseStyle has 1460 observations and all class are found in the training data!\n"
     ]
    }
   ],
   "source": [
    "# HouseStyle: Style of dwelling\n",
    "HouseStyle = {}\n",
    "HouseStyle['1Story'] = 'One story'\n",
    "HouseStyle['1.5Fin'] = 'One and one-half story: 2nd level finished'\n",
    "HouseStyle['1.5Unf'] = 'One and one-half story: 2nd level unfinished'\n",
    "HouseStyle['2Story'] = 'Two story'\n",
    "HouseStyle['2.5Fin'] = 'Two and one-half story: 2nd level finished'\n",
    "HouseStyle['2.5Unf'] = 'Two and one-half story: 2nd level unfinished'\n",
    "HouseStyle['SFoyer'] = 'Split Foyer'\n",
    "HouseStyle['SLvl'] = 'Split Level'\n",
    "\n",
    "a = np.sort(data.HouseStyle.unique())\n",
    "print('HouseStyle has',data.HouseStyle.count(),'observations and all class are found in the training data!')\n",
    "for i in  HouseStyle.keys():\n",
    "   if [i] not in a: print(i, ':', HouseStyle[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention: OverallQual and OverallCond are ordinal data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverallQual has 1460 observations and all class are found in the training data!\n",
      "OverallQual has 1460 . See below the OverallCond not found in the training data:\n",
      "10 : Very Excellent\n"
     ]
    }
   ],
   "source": [
    "# OverallQual: Rates the overall material and finish of the house\n",
    "OverallQual = {}\n",
    "OverallQual[10] = 'Very Excellent'\n",
    "OverallQual[9] = 'Excellent'\n",
    "OverallQual[8] = 'Very Good'\n",
    "OverallQual[7] = 'Good'\n",
    "OverallQual[6] = 'Above Average'\n",
    "OverallQual[5] = 'Average'\n",
    "OverallQual[4] = 'Below Average'\n",
    "OverallQual[3] = 'Fair'\n",
    "OverallQual[2] = 'Poor'\n",
    "OverallQual[1] = 'Very Poor'\n",
    "\n",
    "a = np.sort(data.OverallQual.unique())\n",
    "print('OverallQual has',data.OverallQual.count(),'observations and all class are found in the training data!')\n",
    "for i in  OverallQual.keys():\n",
    "   if [i] not in a: print(i, ':', OverallQual[i])\n",
    "\n",
    "# OverallCond: Rates the overall condition of the house\n",
    "a = np.sort(data.OverallCond.unique())\n",
    "print('OverallQual has',data.OverallCond.count(),\". See below the OverallCond not found in the training data:\")\n",
    "for i in  OverallQual.keys():\n",
    "   if [i] not in a: print(i, ':', OverallQual[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exterior1st has 1460 observations. See below the Exterior1st not found in the training data:\n",
      "Other : Other\n",
      "PreCast : PreCast\n",
      "\n",
      "Exterior2nd has 1460 observations. See below the Exterior2nd not found in the training data:\n",
      "BrkComm : Brick Common\n",
      "CemntBd : Cement Board\n",
      "PreCast : PreCast\n",
      "WdShing : Wood Shingles\n"
     ]
    }
   ],
   "source": [
    "# Exterior1st: Exterior covering on house\n",
    "Exterior1st = {}\n",
    "Exterior1st['AsbShng'] = 'Asbestos Shingles'\n",
    "Exterior1st['AsphShn'] = 'Asphalt Shingles'\n",
    "Exterior1st['BrkComm'] = 'Brick Common'\n",
    "Exterior1st['BrkFace'] = 'Brick Face'\n",
    "Exterior1st['CBlock'] = 'Cinder Block'\n",
    "Exterior1st['CemntBd'] = 'Cement Board'\n",
    "Exterior1st['HdBoard'] = 'Hard Board'\n",
    "Exterior1st['ImStucc'] = 'Imitation Stucco'\n",
    "Exterior1st['MetalSd'] = 'Metal Siding'\n",
    "Exterior1st['Other'] = 'Other'\n",
    "Exterior1st['Plywood'] = 'Plywood'\n",
    "Exterior1st['PreCast'] = 'PreCast'\n",
    "Exterior1st['Stone'] = 'Stone'\n",
    "Exterior1st['Stucco'] = 'Stucco'\n",
    "Exterior1st['VinylSd'] = 'Vinyl Siding'\n",
    "Exterior1st['Wd Sdng'] = 'Wood Siding'\n",
    "Exterior1st['WdShing'] = 'Wood Shingles'\n",
    "\n",
    "a = np.sort(data.Exterior1st.unique())\n",
    "print('Exterior1st has',data.Exterior1st.count(),'observations. See below the Exterior1st not found in the training data:')\n",
    "for i in  Exterior1st.keys():\n",
    "   if [i] not in a: print(i, ':', Exterior1st[i])\n",
    "print()\n",
    "a = np.sort(data.Exterior2nd.unique())\n",
    "print('Exterior2nd has',data.Exterior2nd.count(),'observations. See below the Exterior2nd not found in the training data:')\n",
    "for i in  Exterior1st.keys():\n",
    "   if [i] not in a: print(i, ':', Exterior1st[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention: ExterQual, ExterCond, KitchenQual, FireplaceQu, GarageCond and HeatingQC are ordinals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExterQual has 1460 observations. See below the ExterQual not found in the training data:\n",
      "Po : Poor\n",
      "\n",
      "ExterQual has 1460 observations.\n",
      "\n",
      "HeatingQC has 1460 observations.\n",
      "\n",
      "KitchenQual has 1460 observations. See below the ExterQual not found in the training data:\n",
      "Po : Poor\n",
      "\n",
      "FireplaceQu has 770 observations!\n",
      "\n",
      "GarageCond has 1379 observations!\n"
     ]
    }
   ],
   "source": [
    "# ExterQual: Evaluates the quality of the material on the exterior \n",
    "ExterQual = {}\n",
    "ExterQual['Ex'] = 'Excellent'\n",
    "ExterQual['Gd'] = 'Good'\n",
    "ExterQual['TA'] = 'Average/Typical'\n",
    "ExterQual['Fa'] = 'Fair'\n",
    "ExterQual['Po'] = 'Poor'\n",
    "\n",
    "a = np.sort(data.ExterQual.unique())\n",
    "print('ExterQual has',data.ExterQual.count(),'observations. See below the ExterQual not found in the training data:')\n",
    "for i in  ExterQual.keys():\n",
    "   if [i] not in a: print(i, ':', ExterQual[i])\n",
    "print()\n",
    "\n",
    "# ExterCond: Evaluates the present condition of the material on the exterior\n",
    "a = np.sort(data.ExterCond.unique())\n",
    "print('ExterQual has',data.ExterCond.count(),'observations.')\n",
    "for i in  ExterQual.keys():\n",
    "   if [i] not in a: print(i, ':', ExterQual[i])\n",
    "\n",
    "print()\n",
    "#HeatingQC: Heating quality and condition\n",
    "a = np.sort(data.HeatingQC.unique())\n",
    "print('HeatingQC has',data.HeatingQC.count(),'observations.')\n",
    "for i in  ExterQual.keys():\n",
    "   if [i] not in a: print(i, ':', ExterQual[i])\n",
    "    \n",
    "print()\n",
    "# KitchenQual: Kitchen quality\n",
    "a = np.sort(data.KitchenQual.unique())\n",
    "print('KitchenQual has',data.KitchenQual.count(),'observations. See below the ExterQual not found in the training data:')\n",
    "for i in  ExterQual.keys():\n",
    "   if [i] not in a: print(i, ':', ExterQual[i])\n",
    "    \n",
    "print()\n",
    "# FireplaceQu: Fireplace quality\n",
    "a = (data.FireplaceQu.unique())\n",
    "print('FireplaceQu has',data.FireplaceQu.count(),'observations!')\n",
    "for i in  ExterQual.keys():\n",
    "   if [i] not in a: print(i, ':', ExterQual[i])\n",
    "    \n",
    "print()\n",
    "# GarageCond: Garage Conditionals\n",
    "a = (data.GarageCond.unique())\n",
    "print('GarageCond has',data.GarageCond.count(),'observations!')\n",
    "for i in  ExterQual.keys():\n",
    "   if [i] not in a: print(i, ':', ExterQual[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PavedDrive: Paved driveway is Ordinal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PavedDrive has 1460 observations.\n"
     ]
    }
   ],
   "source": [
    "PavedDrive = {}\n",
    "PavedDrive['Y'] = 'Paved'\n",
    "PavedDrive['P'] = 'Partial Pavement'\n",
    "PavedDrive['N'] = 'Dirt/Gravel'\n",
    "\n",
    "a = np.sort(data.PavedDrive.unique())\n",
    "print('PavedDrive has',data.PavedDrive.count(),'observations.')\n",
    "for i in  PavedDrive.keys():\n",
    "   if [i] not in a: print(i, ':', PavedDrive[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaleType has 1460 observations. See below the SaleType not found in the training data:\n",
      "VWD : Warranty Deed - VA Loan\n"
     ]
    }
   ],
   "source": [
    "# SaleType: Type of sale\n",
    "SaleType = {}\n",
    "SaleType['WD'] = 'Warranty Deed - Conventional'\n",
    "SaleType['CWD'] = 'Warranty Deed - Cash'\n",
    "SaleType['VWD'] = 'Warranty Deed - VA Loan'\n",
    "SaleType['New'] = 'Home just constructed and sold'\n",
    "SaleType['COD'] = 'Court Officer Deed/Estate'\n",
    "SaleType['Con'] = 'Contract 0,15 Down payment regular terms'\n",
    "SaleType['ConLw'] = 'Contract Low Down payment and low interest'\n",
    "SaleType['ConLI'] = 'Contract Low Interest'\n",
    "SaleType['ConLD'] = 'Contract Low Down'\n",
    "SaleType['Oth'] = 'Other'\n",
    "\n",
    "a = np.sort(data.SaleType.unique())\n",
    "print('SaleType has',data.SaleType.count(),'observations. See below the SaleType not found in the training data:')\n",
    "for i in  SaleType.keys():\n",
    "   if [i] not in a: print(i, ':', SaleType[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
